{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": 3
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "<h3>Introduction</h3>\n",
    "\n",
    "Spotify is one of the most popular music streaming service in the world. Songs of various styles and genres are published on the platform by both indie and professional artists from all over the world. As an asprirant artist who is intending to publish his/her song on the platform, one might be interested to predict how much popluarity the song is going to get based on its characteristics such tempo, key or loudness. In this analysis, we're going to look into a Spotify song dataset of 160,000 songs to explore the relationship between features of a song and its popularity. A predictive model will then be built to predict how well a song would do on Spotify based on the song's characteristics.\n",
    "\n",
    "On Spotify, beside song tracks, there are also a great amount of audiobooks, podcast or noise tracks. In this dataset, there is a good mix of different types of tracks so we're going to filter out tracks which are not songs. Only songs data entries will be used to build the predictive model.\n",
    "\n",
    "Lastly, we're going to make a distinction between studio recorded track and live track. Our focus in this analysis is on studio recoded tracks only. Therefore, live session recording shall not be considered."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h3>Dataset</h3>\n",
    "\n",
    "The dataset is named 'Spotify Dataset 1921-2020, 160k+ Tracks' and was published by user Yamac Eren Ay on Kaggle. Homepage of the dataset where details can be found is accessible <a href = 'https://www.kaggle.com/yamaerenay/spotify-dataset-19212020-160k-tracks'>here</a>. \n",
    "\n",
    "It contains more than records of more than 160,000 tracks and was collect using Spotify Web API. There are 19 columns in the dataset, description of each column is as follow:\n",
    "<ul>\n",
    "    <b>Primary:</b>\n",
    "    <br><br>\n",
    "    <li><b style=\"color:Tomato;\">id</b>: string value <br>Unique Spotify identifier for each track</p></li>\n",
    "    <br>\n",
    "    <b>Numerical:</b>\n",
    "    <br><br>\n",
    "    <li><b style=\"color:Tomato;\">acousticness</b>: float value ranges from 0 to 1</li>\n",
    "    Confidence measure of whether the track is acousitc.\n",
    "    <br><br>\n",
    "    <li><b style=\"color:Tomato;\">danceability</b>: float value ranges from 0 to 1</li>\n",
    "    Danceability describes how suitable a track is for dancing based on a combination of musical elements including tempo, rhythm stability, beat strength, and overall regularity. A value of 0.0 is least danceable and 1.0 is most danceable.\n",
    "    <br><br>\n",
    "    <li><b style=\"color:Tomato;\">energy</b>: float value ranges from 0 to 1</li>\n",
    "    Energy is a measure from 0.0 to 1.0 and represents a perceptual measure of intensity and activity. Typically, energetic tracks feel fast, loud, and noisy.\n",
    "    <br><br>\n",
    "    <li><b style=\"color:Tomato;\">duration_ms</b>: integer value, ~250,000 <br>The duration of the track in milliseconds</li>\n",
    "    <br>\n",
    "    <li><b style=\"color:Tomato;\">instrumentalness</b>: (Ranges from 0 to 1)</li>\n",
    "    Predicts whether a track contains no vocals. “Ooh” and “aah” sounds are treated as instrumental in this context. Rap or spoken word tracks are clearly “vocal”. The closer the instrumentalness value is to 1.0, the greater likelihood the track contains no vocal content. Values above 0.5 are intended to represent instrumental tracks, but confidence is higher as the value approaches 1.0.\n",
    "    <br><br>\n",
    "    <li><b style=\"color:Tomato;\">valence</b>: (Ranges from 0 to 1)</li>\n",
    "    A measure from 0.0 to 1.0 describing the musical positiveness conveyed by a track. Tracks with high valence sound more positive (e.g. happy, cheerful, euphoric), while tracks with low valence sound more negative (e.g. sad, depressed, angry).\n",
    "    <br><br>\n",
    "    <li><b style=\"color:Tomato;\">popularity</b>: (Ranges from 0 to 100)</li>\n",
    "    The popularity of a track is a value between 0 and 100, with 100 being the most popular. The popularity is calculated by algorithm and is based, in the most part, on the total number of plays the track has had and how recent those plays are.\n",
    "    <br><br>\n",
    "    <li><b style=\"color:Tomato;\">tempo</b>: (Float typically ranging from 50 to 150)</li>\n",
    "    The overall estimated tempo of a track in beats per minute (BPM). In musical terminology, tempo is the speed or pace of a given piece and derives directly from the average beat duration.\n",
    "    <br><br>\n",
    "    <li><b style=\"color:Tomato;\">liveness</b>: (Ranges from 0 to 1)</li>\n",
    "    Detects the presence of an audience in the recording. Higher liveness values represent an increased probability that the track was performed live. A value above 0.8 provides strong likelihood that the track is live.\n",
    "    <br><br>\n",
    "    <li><b style=\"color:Tomato;\">loudness</b>: (Float typically ranging from -60 to 0)</li>\n",
    "    The overall loudness of a track in decibels (dB). Loudness values are averaged across the entire track and are useful for comparing relative loudness of tracks\n",
    "    <br><br>\n",
    "    <li><b style=\"color:Tomato;\">speechiness</b>: (Ranges from 0 to 1)</li>\n",
    "    Speechiness detects the presence of spoken words in a track. The more exclusively speech-like the recording (e.g. talk show, audio book, poetry), the closer to 1.0 the attribute value. Values above 0.66 describe tracks that are probably made entirely of spoken words. Values between 0.33 and 0.66 describe tracks that may contain both music and speech, either in sections or layered, including such cases as rap music. Values below 0.33 most likely represent music and other non-speech-like tracks.\n",
    "    <br><br>\n",
    "    <li><b style=\"color:Tomato;\">year</b>: (Ranges from 1921 to 2020)</li>\n",
    "    The year a track was published\n",
    "    <br><br>\n",
    "    <b>Dummy:</b>\n",
    "    <br><br>\n",
    "    <li><b style=\"color:Tomato;\">mode</b>: (0 = Minor, 1 = Major)</li>\n",
    "    <br>\n",
    "    <li><b style=\"color:Tomato;\">explicit</b>: (0 = No explicit content, 1 = Explicit content)</li>\n",
    "    <br>\n",
    "    <b>Categorical:</b>\n",
    "    <br><br>\n",
    "    <li><b style=\"color:Tomato;\">key</b>: (All keys on octave encoded as values ranging from 0 to 11, starting on C as 0, C# as 1 and so on…)</li>\n",
    "    <br>\n",
    "    <li><b style=\"color:Tomato;\">artists</b>: (List of artists mentioned)</li>\n",
    "    <br>\n",
    "    <li><b style=\"color:Tomato;\">release_date</b>: (Date of release mostly in yyyy-mm-dd format, however precision of date          may vary)</li>\n",
    "    <br>\n",
    "    <li><b style=\"color:Tomato;\">name</b>: (Name of the track)</li>\n",
    "</ul>\n",
    "\n",
    "Let's take a look at an example record of the song \"Radio Ga Ga\" by \"Queen\". Value of 'key' field being 5 indicates that the song is in key F Major. One interesting feature of this track is 'valence' which the song has a score of 0.632. This tells us that the song is musically positive or, in another word, sounds cheerful and upbeat, which is really the case for the song \"Radio Ga Ga\". Another interesting metric of this song is the 'danceability' score, which it scores an impressive 0.752. This is again understandable since the song, with a simple and catchy beat, is easy to dance to.\n",
    "\n",
    "It is important to note that these numerical metrics are given to each song using Spotify own machine learning model and aren't assigned human so we can assume that scores for different attributes of each song are given fairly consistently. In order to create an actual test case for a new track, it is important to get values for features of interest through Spotify API rather than having someone artist to assign scores to the track based on his/her feeling. More information on Spotify Web API can be found <a href=’ttps://developer.spotify.com/documentation/web-api/reference/tracks/get-audio-features/’>here</a>\n",
    "\n",
    "The key data which describe the attributes of a track such as <b>danceability</b>, <b>acousticness</b>, <b>loudness</b>, ... are already in numerical format and are already normalized so that will help a lot in the data wrangling process. Data field such as 'artists' or 'name', though might very well have an impact on the popularity of a song, will not be used in this model since in the scope of this analysis, we only want to focus on the muscial virtues of a song.\n",
    "\n",
    "The dataset was last updated on 19 June, 2020 so it is still highly relevant at the point of writing of this notebook. However, if this model is to be used at some point in the future, it is recommended to update dataset. Data is valid for the US region only."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import relevant libraries and read data from .csv file\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error, r2_score\n",
    "%matplotlib inline\n",
    "plt.style.use('seaborn')\n",
    "\n",
    "spot = pd.read_csv('data.csv')\n",
    "spot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For the example in 'Dataset' section\n",
    "spot[spot['name']=='Radio Ga Ga']"
   ]
  },
  {
   "source": [
    "<h3>Methodology</h3>\n",
    "First we're going to do some exploratory analysis to have a preliminary understanding of the dataset. Next, we're going to clean up the dataset by filtering out data entries which are not valid, followed by data normalization. \n",
    "Lastly, we're going to select which attributes to use as independent variables in building the predictive model.\n",
    "Since the variable we're trying to predict is a countinuous value, we're going to use a Regression model, more details below."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(spot.shape)\n",
    "print(spot.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot.describe()\n",
    "# no missing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(0, 100, 1)\n",
    "spot.plot(kind='hist', y='popularity', bins=bins)\n",
    "plt.show()\n",
    "print(spot.popularity.value_counts())\n",
    "# there are 27357 tracks with 0 popularity score, which is a disproportinate amount as show in the distribution graph below\n",
    "# Let's investigate the reasons for this 0 rating, keepi in mind that popularity is calculated mostly using counts of listen and how recent those listens are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot_zero = spot[spot.popularity == 0]\n",
    "bins = np.arange(1920, 2021, 1)\n",
    "spot_zero.plot(kind='hist', y='year', bins=bins)\n",
    "plt.show()\n",
    "# It's clear that the majority of the 0-popularity tracks are tracks published before 1960\n",
    "# these songs are probably too old for the current user base (largely millenials) to know about\n",
    "# Therefore, these songs don't receive enough plays to get a popularity score. Some of these \n",
    "# songs might become more popular if somehow the user base decide to give all these old tracks\n",
    "# a try, however there's no way to know for sure. Due to this uncertainty, it's best to drop these\n",
    "# records because there is no relationship between popularity score and a track's attributes\n",
    "\n",
    "print(spot[spot.popularity==0][spot.year==2020][['artists']].squeeze().unique())\n",
    "# There's a small group of tracks published recently but also have a 0 popularity score\n",
    "# A quick querry shows that these tracks are by relatively popular artists so the reason for 0 popularity score\n",
    "# might be because these tracks were released too recently that they haven't got enough time to gather\n",
    "# enough plays to get a score\n",
    "# Same as above, we're going to drop these records. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot[spot.popularity == 0].index\n",
    "spot.drop(index=spot[spot.popularity == 0].index, inplace=True)\n",
    "# drop rows where popularity score = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# According to Spotify API documentation, 'liveness' is defined as detection level of the presence of audience\n",
    "# Higher 'liveness' values indicate a higher probability that a certain track is a record of a live session.\n",
    "# A 'liveness' score of above 0.8 presents a strong likelihood that a track is live.\n",
    "# Since our model is meant to provide prediction for a studio recorded track, we're going to filter and discard\n",
    "# tracks which are highly likely to be live records.\n",
    "\n",
    "print((spot.liveness > 0.8).value_counts())\n",
    "# There are about 3000 tracks in this dataset which are highly likely to be live records\n",
    "spot.drop(index=spot[spot.liveness > 0.8].index, inplace=True)"
   ]
  },
  {
   "source": [
    "We're also not going to use 'liveness' as one of the predicting variables since it's not an attribute\n",
    "which an artist consciously control when creating a track. As far as we're concerned, 'liveness' helps to \n",
    "classify whether a track is live or not and we're not concerned with how whether a track is live or not affects \n",
    "its popularity on Spotify."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# speechiness above 0.66 is considered non-musical so therefore we're going to filter out those tracks as well\n",
    "# unlike 'liveness', 'speechiness' does characterize a track rather than simply classify whether a track is a podcast/talkshow or a song\n",
    "# For example, with 'speechiness' somewhere between 0.33 and 0.66 the song is most likely to be a rap song.\n",
    "# We can see this score as a way to quantify how melodic a song is. Therefore, we're going to keep this column to use as a predicting variable\n",
    "spot.drop(index=spot[spot.speechiness > 0.66].index, inplace=True)\n",
    "spot.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we're going to look into 'tempo' attribute\n",
    "spot.tempo.describe()\n",
    "# We can notice that there are tracks whose tempo is zero, let's list them out\n",
    "spot[spot.tempo == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Interestingly, by actually search for the track on Spotify and listen to it, \n",
    "# we recognize that there are 2 groups of tracks whose tempo is zero\n",
    "# The first group are tracks of noises or sounds such as 'white noise' or 'water sound', which people listen to to focus or relax \n",
    "# The second group comprises tracks which are actually songs for example with tempo but for some reasons, Spotify engine was unable to detect\n",
    "# We assume these data entries are corrupted and going to remove from the dataset\n",
    "spot.drop(index=spot[spot.tempo == 0].index, inplace=True)\n",
    "spot.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename 'duration_ms' column to 'duration'\n",
    "spot.rename(columns={'duration_ms':'duration'}, inplace=True)\n",
    "# We're going to drop colummns not related to the analysis such as 'artists', 'id', 'release_date' & 'name', ...\n",
    "spot.drop(columns=['artists', 'id', 'release_date', 'name', 'liveness', 'year'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalize 'loudness' column\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mms = MinMaxScaler()\n",
    "spot.loc[:, 'loudness'] = mms.fit_transform(spot['loudness'].to_frame())\n",
    "spot.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot.shape\n",
    "# After cleaning the dataset we've arrived with a dataset having 12 features and 1 label column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dependent and independent variables\n",
    "X = spot[['acousticness', 'danceability', 'energy', 'explicit', 'instrumentalness', 'loudness', 'speechiness']].to_numpy()\n",
    "y = spot.popularity.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spot.corr().popularity.plot(kind='bar', ylabel='Correlation')"
   ]
  },
  {
   "source": [
    "We can see there is a relatively strong correlation in 'acousticness', 'energy', 'loudness' and 'explicit'.\n",
    "Interestingy, 'valence' has close to zero bearing on a track's 'popularity', which means whether the theme of the song is 'happy' or 'sad' has little impact on its popularity. A track's 'duration', 'key' and 'mode' and 'tempo' also have close to no influence over popularity\n",
    "\n",
    "Let's explore the relationship with popularity of each individual attributes of interest"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_lr = LinearRegression()\n",
    "s_lr.fit(X[:, 0].reshape(-1, 1), y)\n",
    "corr = spot[['acousticness', 'popularity']].corr().to_numpy()\n",
    "\n",
    "ax = spot.plot(kind='scatter', x='acousticness', y='popularity', figsize=[10, 10])\n",
    "x = np.arange(0, 1, 0.01)\n",
    "y_ = s_lr.intercept_ + s_lr.coef_*x\n",
    "ax.plot(x, y_, color='red')\n",
    "ax.set_title('Correlation between \\'acousticness\\' and \\'popularity\\'')\n",
    "ax.text(0.6, 50, 'Pearson correlation coeff = {:.2f}'.format(corr[0, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_lr = LinearRegression()\n",
    "s_lr.fit(X[:, 1].reshape(-1, 1), y)\n",
    "corr = spot[['danceability', 'popularity']].corr().to_numpy()\n",
    "\n",
    "ax = spot.plot(kind='scatter', x='danceability', y='popularity', figsize=[10, 10])\n",
    "x = np.arange(0, 1, 0.01)\n",
    "y_ = s_lr.intercept_ + s_lr.coef_*x\n",
    "ax.plot(x, y_, color='red')\n",
    "ax.set_title('Correlation between \\'danceability\\' and \\'popularity\\'')\n",
    "ax.text(0.6, 50, 'Pearson correlation coeff = {:.2f}'.format(corr[0, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_lr = LinearRegression()\n",
    "s_lr.fit(X[:, 2].reshape(-1, 1), y)\n",
    "corr = spot[['energy', 'popularity']].corr().to_numpy()\n",
    "\n",
    "ax = spot.plot(kind='scatter', x='energy', y='popularity', figsize=[10, 10])\n",
    "x = np.arange(0, 1, 0.001)\n",
    "y_ = s_lr.intercept_ + s_lr.coef_*x\n",
    "ax.plot(x, y_, color='red')\n",
    "ax.set_title('Correlation between \\'energy\\' and \\'popularity\\'')\n",
    "ax.text(0.2, 40, 'Pearson correlation coeff = {:.2f}'.format(corr[0, 1]))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_lr = LinearRegression()\n",
    "s_lr.fit(X[:, 3].reshape(-1, 1), y)\n",
    "corr = spot[['explicit', 'popularity']].corr().to_numpy()\n",
    "\n",
    "ex0 = spot.groupby('explicit').get_group(0)['popularity']\n",
    "ex1 = spot.groupby('explicit').get_group(1)['popularity']\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "fig.set_size_inches(10, 10)\n",
    "ax.boxplot(x=[ex0, ex1], labels=[0, 1])\n",
    "ax.set_title('Correlation between \\'loudness\\' and \\'popularity\\'')\n",
    "ax.text(1.2, 50, 'Pearson correlation coeff = {:.2f}'.format(corr[0, 1]))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_lr = LinearRegression()\n",
    "s_lr.fit(X[:, 4].reshape(-1, 1), y)\n",
    "corr = spot[['instrumentalness', 'popularity']].corr().to_numpy()\n",
    "\n",
    "ax = spot.plot(kind='scatter', x='instrumentalness', y='popularity', figsize=[10, 10])\n",
    "x = np.arange(0, 1, 0.001)\n",
    "y_ = s_lr.intercept_ + s_lr.coef_*x\n",
    "ax.plot(x, y_, color='red')\n",
    "ax.set_title('Correlation between \\'instrumentalness\\' and \\'popularity\\'')\n",
    "ax.text(0.6, 50, 'Pearson correlation coeff = {:.2f}'.format(corr[0, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_lr = LinearRegression()\n",
    "s_lr.fit(X[:, 5].reshape(-1, 1), y)\n",
    "corr = spot[['loudness', 'popularity']].corr().to_numpy()\n",
    "\n",
    "ax = spot.plot(kind='scatter', x='loudness', y='popularity', figsize=[10, 10])\n",
    "x = np.arange(0, 1, 0.001)\n",
    "y_ = s_lr.intercept_ + s_lr.coef_*x\n",
    "ax.plot(x, y_, color='red')\n",
    "ax.set_title('Correlation between \\'loudness\\' and \\'popularity\\'')\n",
    "ax.text(0.6, 50, 'Pearson correlation coeff = {:.2f}'.format(corr[0, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s_lr = LinearRegression()\n",
    "s_lr.fit(X[:, 6].reshape(-1, 1), y)\n",
    "corr = spot[['speechiness', 'popularity']].corr().to_numpy()\n",
    "\n",
    "ax = spot.plot(kind='scatter', x='speechiness', y='popularity', figsize=[10, 10])\n",
    "x = np.arange(0, 1, 0.001)\n",
    "y_ = s_lr.intercept_ + s_lr.coef_*x\n",
    "ax.plot(x, y_, color='red')\n",
    "ax.set_title('Correlation between \\'speechiness\\' and \\'popularity\\'')\n",
    "ax.text(0.6, 50, 'Pearson correlation coeff = {:.2f}'.format(corr[0, 1]))\n",
    "plt.show()"
   ]
  },
  {
   "source": [
    "We can see from the graphs above that the degree of correlation is not very apparent and a great amount of noise is observed for each case. \n",
    "Now we're going to create train and test set using train_test_split() function from sklearn library"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split into train and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n",
    "\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "source": [
    "Let's now first try to build a prediction model based on a Multiple Linear Regression method and evaluate its accuracy using test set, metrics for accuracy used here are Mean Absolute Error (MAE) score and R2 score"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train, y_train)\n",
    "y_hat = lr.predict(X_test)\n",
    "\n",
    "mean_absolute_error(y_test, y_hat), r2_score(y_test, y_hat)"
   ]
  },
  {
   "source": [
    "Relatively decent score, on average, a prediction for the popularity score of a song is off by +- 12 points. However, we can try to improve evaluation score by trying a Polynomial Regression model\n",
    "\n",
    "Grid search combined with cross validation method is going to be used to pick out the polynomial degree which yields the highest accuracy score."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = PolynomialFeatures(degree=2)\n",
    "lr = LinearRegression()\n",
    "pipe = Pipeline(steps=[('poly', pf), ('reg', lr)])\n",
    "\n",
    "grid = {'poly__degree': [i for i in range(2, 6, 1)]}\n",
    "\n",
    "pf.get_params()\n",
    "search = GridSearchCV(pipe, grid)\n",
    "search.fit(X_train, y_train)\n",
    "print(search.best_score_, search.best_params_)"
   ]
  },
  {
   "source": [
    "A grid search with cross validation scoring return the best polynominal degree for the Polynomial Regression is 4. We're going to set the model parameter to degree=4 and test using test dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h3>Results</h3>"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pf = PolynomialFeatures(degree=4)\n",
    "lr = LinearRegression()\n",
    "pipe = Pipeline(steps=[('poly', pf), ('reg', lr)])\n",
    "\n",
    "pipe.fit(X_train, y_train)\n",
    "y_hat = pipe.predict(X_test)\n",
    "\n",
    "\n",
    "print('Mean absolute score is: {:.2f}'.format(mean_absolute_error(y_test, y_hat)))\n",
    "print('R2 score is: {:.2f}'.format(r2_score(y_test, y_hat)))"
   ]
  },
  {
   "source": [
    "Fairly consistent with scores obtained from cross validation. \n",
    "Now let's assume we're going to compose an EDM track which is, by Spotify model's definition, very danceable, high in energy and relatively loud with a bit of rap. Let's see how well this song can do\n"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = spot[['acousticness', 'danceability', 'energy', 'explicit', 'instrumentalness', 'loudness', 'speechiness']].to_numpy()\n",
    "\n",
    "test = [[0.1, 0.6, 0.8, 1, 0.5, 0.9, 0.2]]\n",
    "\n",
    "print(pipe.predict(test))"
   ]
  },
  {
   "source": [
    "Such a song is predicted to receive a score of 51, which is higher \n",
    "than the mean popularity score of the dataset. Not bad!"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h3>Discussion</h3>\n",
    "An R2 score of around 0.38 indicates that about 38% of the variance of the values in 'popularity' column is explained by the model. Given that this model involves human behaviours and it is in general difficult to explain why or why not a person like something, a 0.38 R2 score is acceptable as to the model's power to predict.\n",
    "\n",
    "It is important to note that this model does not take into account the effect of the popularity of the artist, the size of such artist fanbase (and how much of it are Spotify users), or how a track is marketed. These elements could be a deciding factor as to whether a track can gain the intial traction to become more popular.\n",
    "\n",
    "Another point to note is that this model accuracy depends greatly on how well or how accurately the Spotify machine learning model quantity attributes of a track. For instance, if Spotify model gives a track a 'energy' score of 1 but, in reality, the general perception of the track by the majority of Spotify users who have listened to the song is that it is not very energetic then this data entry will introduce noise into the model.\n",
    "\n",
    "In order to improve this prediction model, more data about how tracks are recommended to Spotify users or how many times is a track listed under different playlists might prove to be useful. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "<h3>Conclusion</h3>\n",
    "\n",
    "In this report we have presented an analysis on the Spotify tracks dataset. We found that there's noticeable correlation between a track's 'popularity' and its attributes such as 'loudness', 'energy' and 'acousticness'\n",
    "A predictive model using Polynomial Regression was then built to predict a song's popularity on Spotify based on its intrinsic characteristics\n",
    "The model achieved a reasonable R-2 score of 0.38"
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}